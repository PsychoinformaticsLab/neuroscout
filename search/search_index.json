{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"What is Neuroscout? Neuroscout is a web-based platform for fast and flexible analysis of fMRI data. Motivation fMRI studies using complex naturalistic stimulation, such as movies or audio narratives, hold great promise to reveal the neural activity underlying dynamic real-world perception. However, this potential utility is constrained by the resource-intensive nature of fMRI analysis, and further exacerbated by the difficulty of encoding relevant events in rich, multi-modal stimuli. Neuroscout leverages state-of-the-art feature extraction tools to automatically extract hundreds of neural predictors from experimental stimuli using a variety of algorithms and content-analysis services. We pair this with an easy-to-use model building interface, enabling researchers to flexibly define novel statistical models. Analysis execution is achieved with no configuration using self-contained bundles tied to unique analysis IDs, and run-time data retrieval using DataLad . Containerized model-fitting pipelines minimize software dependencies and ensure high portability across wide variety execution environments, including HPCs and the cloud. Finally, we make it easy for researchers to share their results with interactive publication-like reports and statistical image hosting with NeuroVault . Where can I get more help? In this documentation, we'll walk you through building and executing your own analysis on neuroscout.org . In addition, the first time you use neuroscout.org, you will be given a tour of the interface. After the tour, be on the look out informational tooltips (\"i\" icon), provided throughout to clarify aspects of the web interface. Finally, please read the FAQ thoroughly! For usage questions not addressed here, please ask a question on NeuroStars . For bug reports, feature requests, feedback, etc., please open an issue on open an issue on GitHub .","title":"Home"},{"location":"#what-is-neuroscout","text":"Neuroscout is a web-based platform for fast and flexible analysis of fMRI data.","title":"What is Neuroscout?"},{"location":"#motivation","text":"fMRI studies using complex naturalistic stimulation, such as movies or audio narratives, hold great promise to reveal the neural activity underlying dynamic real-world perception. However, this potential utility is constrained by the resource-intensive nature of fMRI analysis, and further exacerbated by the difficulty of encoding relevant events in rich, multi-modal stimuli. Neuroscout leverages state-of-the-art feature extraction tools to automatically extract hundreds of neural predictors from experimental stimuli using a variety of algorithms and content-analysis services. We pair this with an easy-to-use model building interface, enabling researchers to flexibly define novel statistical models. Analysis execution is achieved with no configuration using self-contained bundles tied to unique analysis IDs, and run-time data retrieval using DataLad . Containerized model-fitting pipelines minimize software dependencies and ensure high portability across wide variety execution environments, including HPCs and the cloud. Finally, we make it easy for researchers to share their results with interactive publication-like reports and statistical image hosting with NeuroVault .","title":"Motivation"},{"location":"#where-can-i-get-more-help","text":"In this documentation, we'll walk you through building and executing your own analysis on neuroscout.org . In addition, the first time you use neuroscout.org, you will be given a tour of the interface. After the tour, be on the look out informational tooltips (\"i\" icon), provided throughout to clarify aspects of the web interface. Finally, please read the FAQ thoroughly! For usage questions not addressed here, please ask a question on NeuroStars . For bug reports, feature requests, feedback, etc., please open an issue on open an issue on GitHub .","title":"Where can I get more help?"},{"location":"faq/","text":"Frequently Asked Questions Is this service free to use? Yes! Note, however, that Neuroscout is a web-based engine for fMRI analysis specification; at the moment, we don't provide free computing resources for the execution of the resulting analysis bundles. I plan to publish results I've obtained using Neuroscout, how do I cite? After you generate an analysis, a \"Bibliography\" tab will be shown which will auto-generate a reference list for the dataset, feature extractors, and scientific software used for that analysis. In addition to these references, be sure to include the unique analysis ID associated with any results. Are there any restrictions on analyses I've created? Yes. By using Neuroscout, you agree that once you have finalized and \"compiled\" an analysis, the analysis can no longer be deleted from our system. If you wish to 'edit' an Analysis, you may clone the analysis, and make any desired changed on the forked version. Although analyses are by default not searchable by other users, any user with the private analysis ID may view your analysis. Also, in the event that you publish any results generated using the NeuroScout interface, you MUST provide a link to the corresponding analysis page(s) on the NeuroScout website. I have a naturalistic study I'd like to share on Neuroscout, how do I do so? Due to the financial cost of extracting features from multi-modal stimuli using external APIs, the set of datasets we support is manually curated. However, we are continually expanding the list of supported datasets, and we encourage researchers to contact us if they want to make their data available for use in Neuroscout. Note that it is much easier for us to ingest datasets that are already deposited in the OpenNeuro repository, and we we strongly recommend uploading your dataset to OpenNeuro whether or not it eventually ends up in Neuroscout. I want to make changes to an analysis I already ran, but it is locked. How can I edit it? Once an analysis has been run, it is permanently locked and archived for provenance. You may \"clone\" your analysis, and make changes to this new copy of your analysis. I want to make one of my \"private\" analyses public, but the website says the analysis is \"locked\"! When an analysis is locked, you can no longer make any substantive changes that affect model specification. However, you can always edit the name, description, and public/private status. So go ahead and make your analysis public! How do you automatically extract features from naturalistic datasets? The original stimuli presented to users are submitted to various machine learning algorithms and services to extract novel feature timecourses. To facility this process, we have developed a Python library for multimodal feature extraction called pliers. Pliers allows us to extract a wide-variety of features across modalities using various external content analysis services with ease. For example, we are able to use Google Vision API to encode various aspects of the visual elements of movie frames, such as when a face is present. In addition, pliers allows us to easily link up various feature extraction services; for example, we can use the IBM Watson Speech to Text API to transcribe the speech in a movie into words with precise onsets, and then use a predefined dictionary of lexical norms to extract lexical norms for each word, such as frequency. We can then generate timecourses for each of these extracted features, creating novel predictors of brain activity. For more information of pliers, please see the GitHub repository and the following paper: McNamara, Q., De La Vega, A., & Yarkoni, T. (2017, August). Developing a comprehensive framework for multimodal feature extraction. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (pp. 1567-1574). ACM. Am I restricted to mass univariate GLMs, or can I use Neuroscout to specify other kinds of analyses? Currently, that is the case. However,the underlying BIDS-StatsModel is designed with more complex models in mind, such as predictive and linear-mixed effect models","title":"FAQ"},{"location":"faq/#frequently-asked-questions","text":"","title":"Frequently Asked Questions"},{"location":"faq/#is-this-service-free-to-use","text":"Yes! Note, however, that Neuroscout is a web-based engine for fMRI analysis specification; at the moment, we don't provide free computing resources for the execution of the resulting analysis bundles.","title":"Is this service free to use?"},{"location":"faq/#i-plan-to-publish-results-ive-obtained-using-neuroscout-how-do-i-cite","text":"After you generate an analysis, a \"Bibliography\" tab will be shown which will auto-generate a reference list for the dataset, feature extractors, and scientific software used for that analysis. In addition to these references, be sure to include the unique analysis ID associated with any results.","title":"I plan to publish results I've obtained using Neuroscout, how do I cite?"},{"location":"faq/#are-there-any-restrictions-on-analyses-ive-created","text":"Yes. By using Neuroscout, you agree that once you have finalized and \"compiled\" an analysis, the analysis can no longer be deleted from our system. If you wish to 'edit' an Analysis, you may clone the analysis, and make any desired changed on the forked version. Although analyses are by default not searchable by other users, any user with the private analysis ID may view your analysis. Also, in the event that you publish any results generated using the NeuroScout interface, you MUST provide a link to the corresponding analysis page(s) on the NeuroScout website.","title":"Are there any restrictions on analyses I've created?"},{"location":"faq/#i-have-a-naturalistic-study-id-like-to-share-on-neuroscout-how-do-i-do-so","text":"Due to the financial cost of extracting features from multi-modal stimuli using external APIs, the set of datasets we support is manually curated. However, we are continually expanding the list of supported datasets, and we encourage researchers to contact us if they want to make their data available for use in Neuroscout. Note that it is much easier for us to ingest datasets that are already deposited in the OpenNeuro repository, and we we strongly recommend uploading your dataset to OpenNeuro whether or not it eventually ends up in Neuroscout.","title":"I have a naturalistic study I'd like to share on Neuroscout, how do I do so?"},{"location":"faq/#i-want-to-make-changes-to-an-analysis-i-already-ran-but-it-is-locked-how-can-i-edit-it","text":"Once an analysis has been run, it is permanently locked and archived for provenance. You may \"clone\" your analysis, and make changes to this new copy of your analysis.","title":"I want to make changes to an analysis I already ran, but it is locked. How can I edit it?"},{"location":"faq/#i-want-to-make-one-of-my-private-analyses-public-but-the-website-says-the-analysis-is-locked","text":"When an analysis is locked, you can no longer make any substantive changes that affect model specification. However, you can always edit the name, description, and public/private status. So go ahead and make your analysis public!","title":"I want to make one of my \"private\" analyses public, but the website says the analysis is \"locked\"!"},{"location":"faq/#how-do-you-automatically-extract-features-from-naturalistic-datasets","text":"The original stimuli presented to users are submitted to various machine learning algorithms and services to extract novel feature timecourses. To facility this process, we have developed a Python library for multimodal feature extraction called pliers. Pliers allows us to extract a wide-variety of features across modalities using various external content analysis services with ease. For example, we are able to use Google Vision API to encode various aspects of the visual elements of movie frames, such as when a face is present. In addition, pliers allows us to easily link up various feature extraction services; for example, we can use the IBM Watson Speech to Text API to transcribe the speech in a movie into words with precise onsets, and then use a predefined dictionary of lexical norms to extract lexical norms for each word, such as frequency. We can then generate timecourses for each of these extracted features, creating novel predictors of brain activity. For more information of pliers, please see the GitHub repository and the following paper: McNamara, Q., De La Vega, A., & Yarkoni, T. (2017, August). Developing a comprehensive framework for multimodal feature extraction. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (pp. 1567-1574). ACM.","title":"How do you automatically extract features from naturalistic datasets?"},{"location":"faq/#am-i-restricted-to-mass-univariate-glms-or-can-i-use-neuroscout-to-specify-other-kinds-of-analyses","text":"Currently, that is the case. However,the underlying BIDS-StatsModel is designed with more complex models in mind, such as predictive and linear-mixed effect models","title":"Am I restricted to mass univariate GLMs, or can I use Neuroscout to specify other kinds of analyses?"},{"location":"cli/","text":"Neuroscout Coming soon, there will be documentation on how to user Neuroscout here... Overview First section Example command neuroscout run /out 5xhbt","title":"Introduction"},{"location":"cli/#neuroscout","text":"Coming soon, there will be documentation on how to user Neuroscout here...","title":"Neuroscout"},{"location":"cli/#overview","text":"First section","title":"Overview"},{"location":"cli/#example-command","text":"neuroscout run /out 5xhbt","title":"Example command"},{"location":"web/","text":"Using neuroscout.org This user guide will walk you through the neuroscout.org web interface, the primary way you'll interact with Neuroscout. The first aspect we will cover is the analysis builder, which allows you to: Create a custom fMRI analysis from scratch, drawing from hundreds of extracted predictors. Modify predictors by applying transformations, such as scaling and hemodynamic convolution. Define custom contrasts. Iteratively review and modify the statistical model and design matrix. Generate an executable analysis bundle. Once you've learned how to build your own analysis, we'll discuss: Browsing and managing analyses (public and private) Cloning existing analyses to create a forked analysis Viewing and sharing uploaded results Uploading custom predictors Sign Up First things first, you need to register for an account. Currently, there are two supported options, the choice is yours! Create an account using an email address and password (old fashioned way). Use Google single sign on. If you create an account with us, you'll be asked to validate your email, as usual. Note Accounts are linked using email addresses. Signing up twice using the same email address, will result in a single account. Ready to begin? Once you've logged in, you can launch the analysis builder using the New Analysis navigation button. You can use the Browse button to view analyses you've created by selecting My Analyses , or publicly shared analyses under Public analyses . Note that you don't need to log in to view public analyses. Let's get started by creating an analysis using the builder .","title":"Introduction"},{"location":"web/#using-neuroscoutorg","text":"This user guide will walk you through the neuroscout.org web interface, the primary way you'll interact with Neuroscout. The first aspect we will cover is the analysis builder, which allows you to: Create a custom fMRI analysis from scratch, drawing from hundreds of extracted predictors. Modify predictors by applying transformations, such as scaling and hemodynamic convolution. Define custom contrasts. Iteratively review and modify the statistical model and design matrix. Generate an executable analysis bundle. Once you've learned how to build your own analysis, we'll discuss: Browsing and managing analyses (public and private) Cloning existing analyses to create a forked analysis Viewing and sharing uploaded results Uploading custom predictors","title":"Using neuroscout.org"},{"location":"web/#sign-up","text":"First things first, you need to register for an account. Currently, there are two supported options, the choice is yours! Create an account using an email address and password (old fashioned way). Use Google single sign on. If you create an account with us, you'll be asked to validate your email, as usual. Note Accounts are linked using email addresses. Signing up twice using the same email address, will result in a single account.","title":"Sign Up"},{"location":"web/#ready-to-begin","text":"Once you've logged in, you can launch the analysis builder using the New Analysis navigation button. You can use the Browse button to view analyses you've created by selecting My Analyses , or publicly shared analyses under Public analyses . Note that you don't need to log in to view public analyses. Let's get started by creating an analysis using the builder .","title":"Ready to begin?"},{"location":"web/builder/","text":"Analysis Overview When you create a new analysis, you'll launch the analysis builder. You'll sequentially advance through tabs in the builder as you define your analysis. Later in the process, you can always go back to tabs that you've previously encountered, and make modifications. The first step after creating a new analysis is to give it a name . This doesn't have to be a unique name (although that might be helpful), and you can always change it later. Optionally, also give your analysis a description . If you make many analyses, this could be very helpful. Choosing a dataset Neuroscout currently indexes a curated set of nine public naturalstic fMRI datasets. Datasets were specifically chosen for their compliance to the BIDS standard, and availability of original naturalistic stimuli. You can find detailed information on each dataset by clicking on the blue link icon. All datasets are minimally preprocessed using fmriprep 1.2.2 or greater, and ready for model fitting. If you have a dataset you'd like to contribute, see this frequently asked question . Selecting task and runs Once you've selected a dataset, you'll be able to choose which task and runs you want to analyze. Currently, we only support analyzing one task at a time. By default, all runs for that task are selected. If you want to select specific runs to analyze, either to only analyses a group of subjects, or to omit certain runs that might have a known issue, you can use the run selector interface. Here you can browse and select specific runs. If you'd like to select groups of runs based on their BIDS entities (e.g. Subject , Run Number , etc..), click on the filter icon at the top of each column. A drop down menu will appear, allowing you to make a selection. Click \"OK\" to apply this filter. You can clear all filters and select all runs by clicking Clear Filters on the bottom left. Saving and unique ID To save your nascent analysis, click on the \"Save\" button. If the button is blue, that means there are unsaved changes. When you first save your analysis, it will be assigned a unique, permanent ID. Note that when you advance through tabs in the builder, the analysis will be automatically saved. Click on the Next button to advance to the Predictors selection tab. Select Predictors In this tab, you can browse and search from hundreds automatically extracted predictors to include in your model. Predictors each have a unique Name , and belong to a Source . They are also given a human readable Description . In the above example, we have selected the building predictor, that has the source ClarifaiAPIImageExtractor . This is an example of a predictor that was extracted from experimental stimuli. This predictor encodes the probability of a building in a given frame, according to the Clarifai Image Recognition API. You can use the search bar to filter predictors across all three columns. For example, here we searched for \"image recognition\", resulting in 67 matches. As you select predictors, they are displayed in the top right, helping you keep track of predictors not in the current search. You can click on the x on the right of each label to unselect that predictor. Note The predictor interface is your sole interface for adding predictors to the design matrix, including \"confounds\". Since all datasets are pre-processed with fmriprep , use that as a search term to display available confounds. In this example, we have already selected six fmriprep confounds to include in the model (6 rigid-body transforms, such as rot_x ). See the fmriprep documentation for in-depth information about these confound variables. Danger Very large models with dozens of predictors may be slow to compile and fit. We recommend starting with smaller models and building up to larger models as you've gained experience. Add Transformations The next step in defining model is to transform the variables you've selected. This step is optional-- for many models you may not need to make any modifications to the input variables. To add a transformation, click Add Transformation and select an operation from the dropdown list. The transformations currently supported by Neuroscout are a subset of the complete set of transformations detailed in the BIDS StatsModel specification (in active development). As Neuroscout matures, the number of suppport transformations will grow. Transformation Description Scale Standardize the value of one or more variables. Can independently choose to denmean and/or rescale. Orthogonalize Orthogonalizes one or more input columns with respect to one or more other columns. And/Or/Not Each of these transformations takes one or more columns, and performs a logical operation on the input column and a provided operand. Select input For all transformation, you must select on which this transformation will operate. Most operations will operate on each column independently, but specifying multiple columns will save you from having to specify the same operation for multiple predictors. Transformation-specific options Most transformations additional have specific options which you can specify. Scale Demean - If True, subtracts the mean from each input column (i.e., applies mean-centering). Rescale - If True, divides each column by its standard deviation. ReplaceNA - Whether/when to replace missing values with 0. \"Don't replace\"- no replacement is performed. If 'before', missing values are replaced with 0's before scaling. If 'after', missing values are replaced with 0 after scaling. Orthogonalize You must select the inputs to orthogonalize with respect to. The transformed variable will be uncorrelated to these variables. Threshold Threshold - The value to binarize around (values above will be assigned 1, values below will be assigned 0) Binarize - If True, binarizes all non-zero values (i.e., every non-zero value will be set to 1). Above - Specifies which values to retain with respect to the cut-off. If True, all value above the threshold will be kept; if False, all values below the threshold will be kept. Signed - Specifies whether to treat the threshold as signed (default) or unsigned. For example, when passing above=True and threshold=3, if signed=True, all and only values above +3 would be retained. If signed=False, all absolute values > 3 would be retained (i.e.,values in the range -3 < X < 3 would be set to 0). Transformation editing and order It is important to note that transformations are applied sequentially, so the order of the transformation matters. To re-order transformation you can drag and drop transformations in the list. You can also remove transformations you've created using the trash icon, and edit existing transformations with the blue edit icon. HRF Convolution In this tab, you can select which predictors you'd like to convolve with the canonical haemodynamic-response function (HRF). Typically, you'll want to convolve all non-confounds. You can easily do this by clicking Select All Non-Confounds . As in the Predictors tab, you can perform a full-text search over all the predictors you previously selected. For now, we are applying a \"SPM\" style HRF, with no derivatives. Note In reality, HRF convolution is another transformation that is applied after all other transformations. Thus, the transformed variables will be the ones that are convolved. Contrasts In this tab, you can define contrasts to compute at the first-level after the design-matrix is fit to the fMRI activation time-course. As there are often no experimental conditions in naturalistic studies, it often makes the most sense to simply propagate the individual estimates for each predictor of interest (e.g. non-confounds). We can achieve this using \"Dummy\" auto-contrasts, in which each Predictor is given a dummy-coded contrast of the same name. To do this for all non-confounds, simply click Generate Auto Contrasts . Note If you go back to the Predictors tab and edit the predictor list, you may have to re-generate auto contrasts. Defining a custom contrast To define a contrast, click Add Contrast . First, you must give the contrast a name. Next, select the predictors to include in this contrast. All predictors not selected will be given a weight of 0. Finally, enter the weights for the selected predictors. In this example, we are contrasting building and daylight using t contrast. As in the transformations tab, you can re-order, trash, and edit existing contrasts. Review Once you have selected predictors, applied transformations, and defined your contrasts, you're ready to review the statistical model you've designed. Design Report Upon reaching the Review tab, a report is requested from the Neuroscout server that will validate your analysis, apply transformations and pre-compute the design matrix to be fit to the fMRI data. It may take a few minutes to receive the report. Design Matrix Here you can interactively review the final design matrix that will be fit at the first-level of your analysis. The top plot will give you an overview of the design matrix, with each column of the design matrix on the x-axis and time on the y-axis. In the bottom plot, you can explore the predictor time courses in more detail. By clicking on the legend on the right, you can select specific predictors to plot. You may shift-click to select multiple predictors at once. Note For display purposes, each column is standardized prior to the creation of these plots, even if you did not request a scale transformation. This force re-scaling will not be performed when creating the actual design matrix. Correlation Matrix The correlation matrix provides you can opportunity to review the covariance between your predictors. Note that predictors that are highlight correlated with each other may result in a rank deficient design matrix which will cause model fitting to fail. Hint Hover over values in the plot to see the correlation r-values. Analysis Overview Finally, a complete summary of your analysis is displayed in this tab. Here you can review all of the choices you've made and ensure you are happy with the analysis prior to continuing. Note Neuroscout stores your model design using BIDS Stats-Model, an in-development JSON standard for representing fMRI models. This is the true, final representation of your model, so if you are having problems, or would like to meticulously review your analysis, review this section. Run","title":"Analysis builder"},{"location":"web/builder/#analysis-overview","text":"When you create a new analysis, you'll launch the analysis builder. You'll sequentially advance through tabs in the builder as you define your analysis. Later in the process, you can always go back to tabs that you've previously encountered, and make modifications. The first step after creating a new analysis is to give it a name . This doesn't have to be a unique name (although that might be helpful), and you can always change it later. Optionally, also give your analysis a description . If you make many analyses, this could be very helpful.","title":"Analysis Overview"},{"location":"web/builder/#choosing-a-dataset","text":"Neuroscout currently indexes a curated set of nine public naturalstic fMRI datasets. Datasets were specifically chosen for their compliance to the BIDS standard, and availability of original naturalistic stimuli. You can find detailed information on each dataset by clicking on the blue link icon. All datasets are minimally preprocessed using fmriprep 1.2.2 or greater, and ready for model fitting. If you have a dataset you'd like to contribute, see this frequently asked question .","title":"Choosing a dataset"},{"location":"web/builder/#selecting-task-and-runs","text":"Once you've selected a dataset, you'll be able to choose which task and runs you want to analyze. Currently, we only support analyzing one task at a time. By default, all runs for that task are selected. If you want to select specific runs to analyze, either to only analyses a group of subjects, or to omit certain runs that might have a known issue, you can use the run selector interface. Here you can browse and select specific runs. If you'd like to select groups of runs based on their BIDS entities (e.g. Subject , Run Number , etc..), click on the filter icon at the top of each column. A drop down menu will appear, allowing you to make a selection. Click \"OK\" to apply this filter. You can clear all filters and select all runs by clicking Clear Filters on the bottom left.","title":"Selecting task and runs"},{"location":"web/builder/#saving-and-unique-id","text":"To save your nascent analysis, click on the \"Save\" button. If the button is blue, that means there are unsaved changes. When you first save your analysis, it will be assigned a unique, permanent ID. Note that when you advance through tabs in the builder, the analysis will be automatically saved. Click on the Next button to advance to the Predictors selection tab.","title":"Saving and unique ID"},{"location":"web/builder/#select-predictors","text":"In this tab, you can browse and search from hundreds automatically extracted predictors to include in your model. Predictors each have a unique Name , and belong to a Source . They are also given a human readable Description . In the above example, we have selected the building predictor, that has the source ClarifaiAPIImageExtractor . This is an example of a predictor that was extracted from experimental stimuli. This predictor encodes the probability of a building in a given frame, according to the Clarifai Image Recognition API. You can use the search bar to filter predictors across all three columns. For example, here we searched for \"image recognition\", resulting in 67 matches. As you select predictors, they are displayed in the top right, helping you keep track of predictors not in the current search. You can click on the x on the right of each label to unselect that predictor. Note The predictor interface is your sole interface for adding predictors to the design matrix, including \"confounds\". Since all datasets are pre-processed with fmriprep , use that as a search term to display available confounds. In this example, we have already selected six fmriprep confounds to include in the model (6 rigid-body transforms, such as rot_x ). See the fmriprep documentation for in-depth information about these confound variables. Danger Very large models with dozens of predictors may be slow to compile and fit. We recommend starting with smaller models and building up to larger models as you've gained experience.","title":"Select Predictors"},{"location":"web/builder/#add-transformations","text":"The next step in defining model is to transform the variables you've selected. This step is optional-- for many models you may not need to make any modifications to the input variables. To add a transformation, click Add Transformation and select an operation from the dropdown list. The transformations currently supported by Neuroscout are a subset of the complete set of transformations detailed in the BIDS StatsModel specification (in active development). As Neuroscout matures, the number of suppport transformations will grow. Transformation Description Scale Standardize the value of one or more variables. Can independently choose to denmean and/or rescale. Orthogonalize Orthogonalizes one or more input columns with respect to one or more other columns. And/Or/Not Each of these transformations takes one or more columns, and performs a logical operation on the input column and a provided operand.","title":"Add Transformations"},{"location":"web/builder/#select-input","text":"For all transformation, you must select on which this transformation will operate. Most operations will operate on each column independently, but specifying multiple columns will save you from having to specify the same operation for multiple predictors.","title":"Select input"},{"location":"web/builder/#transformation-specific-options","text":"Most transformations additional have specific options which you can specify.","title":"Transformation-specific options"},{"location":"web/builder/#scale","text":"Demean - If True, subtracts the mean from each input column (i.e., applies mean-centering). Rescale - If True, divides each column by its standard deviation. ReplaceNA - Whether/when to replace missing values with 0. \"Don't replace\"- no replacement is performed. If 'before', missing values are replaced with 0's before scaling. If 'after', missing values are replaced with 0 after scaling.","title":"Scale"},{"location":"web/builder/#orthogonalize","text":"You must select the inputs to orthogonalize with respect to. The transformed variable will be uncorrelated to these variables.","title":"Orthogonalize"},{"location":"web/builder/#threshold","text":"Threshold - The value to binarize around (values above will be assigned 1, values below will be assigned 0) Binarize - If True, binarizes all non-zero values (i.e., every non-zero value will be set to 1). Above - Specifies which values to retain with respect to the cut-off. If True, all value above the threshold will be kept; if False, all values below the threshold will be kept. Signed - Specifies whether to treat the threshold as signed (default) or unsigned. For example, when passing above=True and threshold=3, if signed=True, all and only values above +3 would be retained. If signed=False, all absolute values > 3 would be retained (i.e.,values in the range -3 < X < 3 would be set to 0).","title":"Threshold"},{"location":"web/builder/#transformation-editing-and-order","text":"It is important to note that transformations are applied sequentially, so the order of the transformation matters. To re-order transformation you can drag and drop transformations in the list. You can also remove transformations you've created using the trash icon, and edit existing transformations with the blue edit icon.","title":"Transformation editing and order"},{"location":"web/builder/#hrf-convolution","text":"In this tab, you can select which predictors you'd like to convolve with the canonical haemodynamic-response function (HRF). Typically, you'll want to convolve all non-confounds. You can easily do this by clicking Select All Non-Confounds . As in the Predictors tab, you can perform a full-text search over all the predictors you previously selected. For now, we are applying a \"SPM\" style HRF, with no derivatives. Note In reality, HRF convolution is another transformation that is applied after all other transformations. Thus, the transformed variables will be the ones that are convolved.","title":"HRF Convolution"},{"location":"web/builder/#contrasts","text":"In this tab, you can define contrasts to compute at the first-level after the design-matrix is fit to the fMRI activation time-course. As there are often no experimental conditions in naturalistic studies, it often makes the most sense to simply propagate the individual estimates for each predictor of interest (e.g. non-confounds). We can achieve this using \"Dummy\" auto-contrasts, in which each Predictor is given a dummy-coded contrast of the same name. To do this for all non-confounds, simply click Generate Auto Contrasts . Note If you go back to the Predictors tab and edit the predictor list, you may have to re-generate auto contrasts.","title":"Contrasts"},{"location":"web/builder/#defining-a-custom-contrast","text":"To define a contrast, click Add Contrast . First, you must give the contrast a name. Next, select the predictors to include in this contrast. All predictors not selected will be given a weight of 0. Finally, enter the weights for the selected predictors. In this example, we are contrasting building and daylight using t contrast. As in the transformations tab, you can re-order, trash, and edit existing contrasts.","title":"Defining a custom contrast"},{"location":"web/builder/#review","text":"Once you have selected predictors, applied transformations, and defined your contrasts, you're ready to review the statistical model you've designed.","title":"Review"},{"location":"web/builder/#design-report","text":"Upon reaching the Review tab, a report is requested from the Neuroscout server that will validate your analysis, apply transformations and pre-compute the design matrix to be fit to the fMRI data. It may take a few minutes to receive the report.","title":"Design Report"},{"location":"web/builder/#design-matrix","text":"Here you can interactively review the final design matrix that will be fit at the first-level of your analysis. The top plot will give you an overview of the design matrix, with each column of the design matrix on the x-axis and time on the y-axis. In the bottom plot, you can explore the predictor time courses in more detail. By clicking on the legend on the right, you can select specific predictors to plot. You may shift-click to select multiple predictors at once. Note For display purposes, each column is standardized prior to the creation of these plots, even if you did not request a scale transformation. This force re-scaling will not be performed when creating the actual design matrix.","title":"Design Matrix"},{"location":"web/builder/#correlation-matrix","text":"The correlation matrix provides you can opportunity to review the covariance between your predictors. Note that predictors that are highlight correlated with each other may result in a rank deficient design matrix which will cause model fitting to fail. Hint Hover over values in the plot to see the correlation r-values.","title":"Correlation Matrix"},{"location":"web/builder/#analysis-overview_1","text":"Finally, a complete summary of your analysis is displayed in this tab. Here you can review all of the choices you've made and ensure you are happy with the analysis prior to continuing. Note Neuroscout stores your model design using BIDS Stats-Model, an in-development JSON standard for representing fMRI models. This is the true, final representation of your model, so if you are having problems, or would like to meticulously review your analysis, review this section.","title":"Analysis Overview"},{"location":"web/builder/#run","text":"","title":"Run"}]}